{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef96a20-a5d8-4fcb-bbb5-b1010ad46c31",
   "metadata": {},
   "source": [
    "## Check Spark kernel connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a89499-4cbd-4044-8f53-3b8d0df34968",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa46f4-8ae8-43a4-8d6b-e34b04ea2e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a65ceee-fcae-49cb-ad68-9d28e792f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ad93a7-480d-42ce-ac47-cdbc4c8fb03d",
   "metadata": {},
   "source": [
    "### Check if it is able to connect to Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8102280e-04e2-4339-b5d6-e6b94a29cb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbdata = spark.sql(\"SELECT * FROM schema.table LIMIT 50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb18b3-0ff5-4da6-8190-582ca0ab3f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_cnbdata = cnbdata.toPandas()\n",
    "\n",
    "# pandas_datehour_totals.set_index('datehour', inplace=True)\n",
    "pandas_cnbdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e51e68-67fe-4bca-82a5-48a42c0e06b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('error', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5239ccb-e2e6-43a2-b2ca-af1480b02767",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --force-reinstall flask-sqlalchemy sqlalchemy\n",
    "!pip install pyspark-ai\n",
    "!pip install google-cloud-aiplatform\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499de2d5-3253-4b16-8885-edb0b5b13bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae1d19-d377-4a5d-8d45-d4cc5b5390e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "#Just to avoid the warnings\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"junk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff1c179-1d5c-43bd-a8e2-07dc6867845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
    "REGION = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9d431-fcee-4203-bb49-fc2493832bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "# from langchain.llms import VertexAI\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "# from langchain.chat_models import ChatVertexAI\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from google.cloud import aiplatform\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# LangChain\n",
    "import langchain\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from pyspark.sql.functions import expr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caabcded-5af3-4df6-a1db-89601525e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"LangChain version: {langchain.__version__}\")\n",
    "\n",
    "# Vertex AI\n",
    "\n",
    "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5023b6ae-6f6e-4d08-a202-e32b011005cd",
   "metadata": {},
   "source": [
    "### Initialization \n",
    "#### (chat-bison@002 has little issues in udf usecase and Below model release date was 2023-07-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f127b7f-070b-4505-9985-934cec916457",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat1 = ChatVertexAI(\n",
    "    model_name=\"chat-bison@001\", max_output_tokens=1000, temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9551cd56-6c15-42ed-8248-5314b006aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat2 = ChatVertexAI(\n",
    "    model_name=\"chat-bison@002\", max_output_tokens=1000, temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e9b376-1e5e-4189-865c-001de3c17b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark_ai import SparkAI\n",
    "\n",
    "spark_ai = SparkAI(llm=chat1,verbose=True)\n",
    "spark_ai.activate()  # active partial functions for Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18794d3-5165-4485-9e0f-efc50fdd34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbdata.ai.transform(\"get me all the names?\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fb0fe8-79c0-455b-b94e-ec6474ee6af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbdata.ai.transform(\"List all the married persons?\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d7c288-2827-4569-a788-13e5d11b05ec",
   "metadata": {},
   "source": [
    "### Only for udf we use chat-bison@001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e1d3f-f775-4755-ad55-c1301b0e4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark_ai import SparkAI\n",
    "\n",
    "spark_ai = SparkAI(llm=chat1,verbose=True)\n",
    "spark_ai.activate() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4918363-a3e6-4b9e-a737-5cdf31ea5e80",
   "metadata": {},
   "source": [
    "### Now lets create udf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02776021-8c88-49d2-af90-3ebbd10829d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@spark_ai.udf\n",
    "def full_name(first_name: str, last_name: str) -> str:\n",
    "    \"\"\"combine first name and last name.\n",
    "       If field is missing replace it by None. All imports should be inside function.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a3c72-4231-44ae-ba6b-6a69441467fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import col, udf\n",
    "\n",
    "spark.udf.register(\"full_name\", full_name, returnType=StringType())\n",
    "results = (\n",
    "    cnbdata\n",
    "    .withColumn(\"first_name\", col(\"first_name\"))\n",
    "    .withColumn(\"last_name\", col(\"last_name\"))\n",
    "    .withColumn(\"full_name\", expr(\"full_name(first_name, last_name)\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a43273-b322-4204-badf-759dbd0b526f",
   "metadata": {},
   "source": [
    "### test the udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f6551a-eef5-490a-9e62-8cfcaf7a997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da016f91-7a06-4973-a8d6-d4819025e001",
   "metadata": {},
   "source": [
    "### Transform Accuracy Improvement: Vector Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a5b7a-240a-4cb0-9d94-d2a70a20716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@spark_ai.udf\n",
    "def full_name(first_name: str, last_name: str) -> str:\n",
    "    \"\"\"combine first name and last name. Based on Gender add Prefix.\n",
    "       If field is missing replace it by None. All imports should be inside function.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edfe729-7eb8-4046-ad4e-935759fc852c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
